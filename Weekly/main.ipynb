{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f50b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "# 1. Load Datasets\n",
    "df_purchase = pd.read_csv(\"User_product_purchase_details_p2.csv\")\n",
    "df_user = pd.read_csv(\"user_demographics.csv\")\n",
    "\n",
    "df = pd.merge(df_purchase, df_user, on=\"User_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1186dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create Target Column\n",
    "df[\"High_Value_Purchase\"] = (df[\"Purchase\"] >= 10000).astype(int)\n",
    "\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fc025e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unused column\n",
    "if \"Product_ID\" in df.columns:\n",
    "    df = df.drop(\"Product_ID\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d511f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Encode Categorical Columns\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[col] = le.fit_transform(df[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36c48a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train-Test Split\n",
    "X = df.drop([\"High_Value_Purchase\", \"Purchase\"], axis=1)\n",
    "y = df[\"High_Value_Purchase\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be61cd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Scale Numeric Columns\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f95c132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Logistic Regression ----------------\n",
      "Accuracy: 0.7667569582053193\n",
      "[[64634  7472]\n",
      " [18188 19720]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.83     72106\n",
      "           1       0.73      0.52      0.61     37908\n",
      "\n",
      "    accuracy                           0.77    110014\n",
      "   macro avg       0.75      0.71      0.72    110014\n",
      "weighted avg       0.76      0.77      0.76    110014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Logistic Regression\n",
    "print(\"\\n---------------- Logistic Regression ----------------\")\n",
    "lr = LogisticRegression(max_iter=2000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "pred_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_lr))\n",
    "print(confusion_matrix(y_test, pred_lr))\n",
    "print(classification_report(y_test, pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f83dfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Random Forest ----------------\n",
      "Accuracy: 0.892150089988547\n",
      "[[64926  7180]\n",
      " [ 4685 33223]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92     72106\n",
      "           1       0.82      0.88      0.85     37908\n",
      "\n",
      "    accuracy                           0.89    110014\n",
      "   macro avg       0.88      0.89      0.88    110014\n",
      "weighted avg       0.89      0.89      0.89    110014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Random Forest\n",
    "print(\"\\n---------------- Random Forest ----------------\")\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "pred_rf = rf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_rf))\n",
    "print(confusion_matrix(y_test, pred_rf))\n",
    "print(classification_report(y_test, pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e42932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- XGBoost ----------------\n",
      "Accuracy: 0.9022942534586507\n",
      "[[63137  8969]\n",
      " [ 1780 36128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92     72106\n",
      "           1       0.80      0.95      0.87     37908\n",
      "\n",
      "    accuracy                           0.90    110014\n",
      "   macro avg       0.89      0.91      0.90    110014\n",
      "weighted avg       0.91      0.90      0.90    110014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8. XGBoost\n",
    "\n",
    "print(\"\\n---------------- XGBoost ----------------\")\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    eval_metric=\"logloss\"\n",
    ")\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_xgb))\n",
    "print(confusion_matrix(y_test, pred_xgb))\n",
    "print(classification_report(y_test, pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1aa4130c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Keras MLP ----------------\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\Weekly\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6876/6876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 991us/step - loss: 0.3474 - precision: 0.7838\n",
      "Epoch 2/10\n",
      "\u001b[1m6876/6876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735us/step - loss: 0.2862 - precision: 0.7888\n",
      "Epoch 3/10\n",
      "\u001b[1m6876/6876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 774us/step - loss: 0.2734 - precision: 0.7890\n",
      "Epoch 4/10\n",
      "\u001b[1m6876/6876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 815us/step - loss: 0.2651 - precision: 0.7904\n",
      "Epoch 5/10\n",
      "\u001b[1m6876/6876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 805us/step - loss: 0.2607 - precision: 0.7910\n",
      "Epoch 6/10\n",
      "\u001b[1m6876/6876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 776us/step - loss: 0.2582 - precision: 0.7925\n",
      "Epoch 7/10\n",
      "\u001b[1m6876/6876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 816us/step - loss: 0.2564 - precision: 0.7934\n",
      "Epoch 8/10\n",
      "\u001b[1m6876/6876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 796us/step - loss: 0.2546 - precision: 0.7936\n",
      "Epoch 9/10\n",
      "\u001b[1m6876/6876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 792us/step - loss: 0.2529 - precision: 0.7942\n",
      "Epoch 10/10\n",
      "\u001b[1m6876/6876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 813us/step - loss: 0.2523 - precision: 0.7947\n",
      "\u001b[1m3438/3438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 454us/step\n",
      "Accuracy: 0.8977857363608268\n",
      "[[62670  9436]\n",
      " [ 1809 36099]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92     72106\n",
      "           1       0.79      0.95      0.87     37908\n",
      "\n",
      "    accuracy                           0.90    110014\n",
      "   macro avg       0.88      0.91      0.89    110014\n",
      "weighted avg       0.91      0.90      0.90    110014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. Keras MLP\n",
    "print(\"\\n---------------- Keras MLP ----------------\")\n",
    "\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(128, activation=\"relu\", input_shape=(input_dim,)),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"precision\"])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=64, verbose=1)\n",
    "\n",
    "pred_mlp_prob = model.predict(X_test_scaled).flatten()\n",
    "pred_mlp = (pred_mlp_prob >= 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_mlp))\n",
    "print(confusion_matrix(y_test, pred_mlp))\n",
    "print(classification_report(y_test, pred_mlp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
